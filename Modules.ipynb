{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules\n",
    "This file contains modules that may be used for data manipulation, transformation, and feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "## load the dataset into dataframe\n",
    "\n",
    "    import pandas as pd\n",
    "    houses = pd.read_csv(filepath)\n",
    "#     print('There are {} samples with {} features: {}.'.format(houses.shape[0], houses.shape[1]-2, houses.columns.values))\n",
    "    return houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_variable_features(data):\n",
    "## separate features and saleprice\n",
    "\n",
    "    y = data['SalePrice']\n",
    "    X = data.drop('SalePrice',1)\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_NA(houses):\n",
    "## Drop the 'Id', 'MiscFeature', 'GarageCars' features\n",
    "## Drop the one sample with missing 'Electrical' information\n",
    "## Fill all other NA with 'None' (categorical) or 0 (numerical)\n",
    "\n",
    "    feature_fillNA_drop = ['MiscFeature','GarageCars']\n",
    "    houses = houses.drop(feature_fillNA_drop,1)\n",
    "    from statistics import mode\n",
    "    feature_fillNA_with_none = ['PoolQC','Alley','Fence','FireplaceQu','GarageCond','GarageType','GarageYrBlt','GarageFinish',\n",
    "                                'GarageQual','BsmtQual','BsmtCond','BsmtFinType1','BsmtFinType2','BsmtExposure','MasVnrType',\n",
    "                                'Street','LotShape','LandContour','KitchenQual','Functional']\n",
    "    feature_fillNA_with_mode = ['LotFrontage','MSZoning','Electrical','MSSubClass','Utilities','SaleType']\n",
    "    feature_fillNA_with_zero = ['MasVnrArea','LotArea','Exterior1st','Exterior2nd','PoolArea','BsmtFullBath','BsmtHalfBath',\n",
    "                                'GarageArea','BsmtFinSF2','BsmtFinSF1','TotalBsmtSF','BsmtUnfSF']\n",
    "    \n",
    "    houses[feature_fillNA_with_none] = houses[feature_fillNA_with_none].fillna('None')\n",
    "    houses[feature_fillNA_with_mode] = houses[feature_fillNA_with_mode].fillna(houses[feature_fillNA_with_mode].mode().loc[0])\n",
    "    houses[feature_fillNA_with_zero] = houses[feature_fillNA_with_zero].fillna(0.0)\n",
    "#     # Remove the sample with missing Electrical informaiton\n",
    "#     idx_naElectrical = houses.loc[houses['Electrical'].isnull()].index\n",
    "#     houses = houses.drop(idx_naElectrical)\n",
    "#     print('After filling NAs, There are {} samples with {} features: {}.'.format(houses.shape[0], houses.shape[1]-2, houses.columns.values))\n",
    "    return houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def redefine_category_numeric(data):\n",
    "## change some categorical feature into numerical feature to show the quality/condition order and for further feature engineering\n",
    "## change some numerical feature into categorical feature, 'MSSubClass', 'MoSold', 'YrSold'\n",
    "\n",
    "#     categorical_features = data.select_dtypes(include = [\"object\"]).columns\n",
    "#     numerical_features = data.select_dtypes(exclude = [\"object\"]).columns\n",
    "    data = data.replace({\"MSSubClass\" : {20 : \"SC20\", 30 : \"SC30\", 40 : \"SC40\", 45 : \"SC45\", \n",
    "                                       50 : \"SC50\", 60 : \"SC60\", 70 : \"SC70\", 75 : \"SC75\", \n",
    "                                       80 : \"SC80\", 85 : \"SC85\", 90 : \"SC90\", 120 : \"SC120\", \n",
    "                                       150 : \"SC150\", 160 : \"SC160\", 180 : \"SC180\", 190 : \"SC190\"},\n",
    "                       \"MoSold\" : {1 : \"Jan\", 2 : \"Feb\", 3 : \"Mar\", 4 : \"Apr\", 5 : \"May\", 6 : \"Jun\",\n",
    "                                   7 : \"Jul\", 8 : \"Aug\", 9 : \"Sep\", 10 : \"Oct\", 11 : \"Nov\", 12 : \"Dec\"},\n",
    "                       \"YrSold\": {2008:'2008', 2007:'2007',2006:'2006',2009:'2009',2010:'2010'}\n",
    "                      })\n",
    "    data = data.replace({\n",
    "#                         \"Street\" : {\"Grvl\" : 1, \"Pave\" : 2},\n",
    "#                         \"Alley\" : {\"None\" : 0, \"Grvl\" : 1, \"Pave\" : 2},\n",
    "                        \"ExterQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                        \"ExterCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\": 4, \"Ex\" : 5},\n",
    "                        \"BsmtQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\": 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"BsmtCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "#                         \"BsmtExposure\" : {\"None\" : 0, \"Mn\" : 1, \"Av\": 2, \"Gd\" : 3},\n",
    "                        \"BsmtFinType1\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                        \"BsmtFinType2\" : {\"None\" : 0, \"Unf\" : 1, \"LwQ\": 2, \"Rec\" : 3, \"BLQ\" : 4, \n",
    "                                         \"ALQ\" : 5, \"GLQ\" : 6},\n",
    "                        \"HeatingQC\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"KitchenQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"Functional\" : {\"None\" : 0, \"Sal\" : 1, \"Sev\" : 2, \"Maj2\" : 3, \"Maj1\" : 4, \"Mod\": 5, \n",
    "                                       \"Min2\" : 6, \"Min1\" : 7, \"Typ\" : 8},\n",
    "                        \"FireplaceQu\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"GarageFinish\" : {\"None\" : 0, \"Unf\" : 1, \"RFn\" : 2, \"Fin\" : 3},\n",
    "                        \"GarageQual\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "                        \"GarageCond\" : {\"None\" : 0, \"Po\" : 1, \"Fa\" : 2, \"TA\" : 3, \"Gd\" : 4, \"Ex\" : 5},\n",
    "#                         \"PavedDrive\" : {\"N\" : 0, \"P\" : 1, \"Y\" : 2},\n",
    "                        \"PoolQC\" : {\"None\" : 0, \"Fa\" : 1, \"TA\" : 2, \"Gd\" : 3, \"Ex\" : 4},\n",
    "#                         \"Fence\" : {\"None\" : 0, \"MnWw\" : 1, \"MnPrv\" : 1, \"GdWo\" : 2, \"GdPrv\" : 2}\n",
    "                        })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_new_features(houses):\n",
    "## create new features from combination of existing features\n",
    "## remove the corresponding features\n",
    "\n",
    "    houses['Overall'] = houses['OverallQual'] * houses['OverallCond'] * houses['Functional']\n",
    "    houses['Pool'] = houses['PoolQC'] * houses['PoolArea']\n",
    "    houses['Exter'] = houses['ExterQual'] * houses['ExterCond']\n",
    "    houses['Kitchen'] = houses['KitchenAbvGr'] * houses['KitchenQual']\n",
    "    houses['Garage'] = houses['GarageQual'] * houses['GarageCond'] * houses['GarageFinish'] * houses['GarageArea']\n",
    "    houses['Fireplace'] = houses['Fireplaces'] * houses['FireplaceQu']\n",
    "    houses['Basement'] = houses['BsmtQual'] * houses['BsmtCond'] * (houses['BsmtFinType1']*houses['BsmtFinSF1']+houses['BsmtFinType2']*houses['BsmtFinSF2']+houses['BsmtUnfSF'])/houses['TotalBsmtSF']\n",
    "    houses['Basement'] = houses['Basement'].fillna(0)\n",
    "    houses['OpenAreaSF'] = houses['WoodDeckSF'] + houses['OpenPorchSF'] + houses['EnclosedPorch'] + houses['3SsnPorch'] + houses['ScreenPorch']\n",
    "    houses['TotBath'] = houses[\"BsmtFullBath\"] + (0.5 * houses[\"BsmtHalfBath\"]) + houses[\"FullBath\"] + (0.5 * houses[\"HalfBath\"])\n",
    "    houses['TotSF'] = houses['GrLivArea'] + houses['TotalBsmtSF']\n",
    "    \n",
    "    \n",
    "    houses = houses.drop(['OverallQual','OverallCond','Functional'],1)  \n",
    "    houses = houses.drop(['PoolQC','PoolArea'],1)    \n",
    "    houses = houses.drop(['ExterQual','ExterCond'],1)    \n",
    "    houses = houses.drop(['KitchenAbvGr','KitchenQual'],1)    \n",
    "    houses = houses.drop(['GarageQual','GarageCond','GarageFinish','GarageArea'],1)    \n",
    "    houses = houses.drop(['Fireplaces','FireplaceQu'],1)    \n",
    "    houses = houses.drop(['BsmtQual','BsmtCond','BsmtFinType1','BsmtFinSF1','BsmtFinType2','BsmtFinSF2'],1)    \n",
    "    houses = houses.drop(['WoodDeckSF','OpenPorchSF','EnclosedPorch','3SsnPorch','ScreenPorch'],1)\n",
    "    houses = houses.drop([\"BsmtFullBath\",\"BsmtHalfBath\",'FullBath','HalfBath'],1)\n",
    "    \n",
    "    return houses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def log_transform_skew(data):\n",
    "## using log-transformation to make the features more like normal distribution (less sknewness)\n",
    "## better regression result to smooth out some irregularities\n",
    "    \n",
    "    import numpy as np\n",
    "    log_transform_features = ['LotFrontage','LotArea','MasVnrArea','1stFlrSF','2ndFlrSF','GrLivArea',\n",
    "                              'Exter','Kitchen','Fireplace','Basement','TotSF']\n",
    "    data[log_transform_features] = np.log1p(data[log_transform_features])\n",
    "    data['BsmtUnfSF'] = np.log(data['BsmtUnfSF']+500)\n",
    "    data['TotalBsmtSF'] = np.log(data['TotalBsmtSF']+1000)\n",
    "    data['Garage'] = np.log(data['Garage']+500)\n",
    "    data['Basement'] = np.log(data['Basement']+500)\n",
    "    data['OpenAreaSF'] = np.log(data['OpenAreaSF']+500)\n",
    "    data['Overall'] = np.log(data['Overall']+300)\n",
    "    \n",
    "    data['YearBuilt'] = data['YearBuilt']/1000\n",
    "    data['YearRemodAdd'] = data['YearRemodAdd']/1000\n",
    "    \n",
    "    data = data.drop(['LowQualFinSF','MiscVal','Pool'],1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_scaling_numeric_features(data):\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    feature = ['LotFrontage','LotArea','1stFlrSF','GrLivArea',\n",
    "               'Exter','Kitchen','Basement','TotSF','BsmtUnfSF','TotalBsmtSF',\n",
    "               'Garage','Basement','OpenAreaSF']\n",
    "    stdSc = StandardScaler()\n",
    "    data.loc[:, feature] = stdSc.fit_transform(data.loc[:, feature])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def robust_scaling_numeric_features(data):\n",
    "    from sklearn.preprocessing import RobustScaler\n",
    "    feature = ['LotFrontage','LotArea','1stFlrSF','GrLivArea',\n",
    "               'Exter','Kitchen','Basement','TotSF','BsmtUnfSF','TotalBsmtSF',\n",
    "               'Garage','Basement','OpenAreaSF']\n",
    "    rSc = RobustScaler()\n",
    "    data.loc[:, feature] = rSc.fit_transform(data.loc[:, feature])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_category_features(data):\n",
    "    import pandas as pd\n",
    "    data = pd.get_dummies(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, ShuffleSplit, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better = False)\n",
    "import numpy as np\n",
    "def rmse_cv(model):\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "#     cv = 10\n",
    "    rmse = np.sqrt(-cross_val_score(model, X_training, y, scoring = scorer, cv=cv))\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_regression():\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(X_train, y_train)\n",
    "    print(\"RMSE for Linear Regression: {:0.4f} (+/- {:0.4f})\".format(rmse_cv(lr).mean(), rmse_cv(lr).std() * 2))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression():\n",
    "    from sklearn.linear_model import RidgeCV\n",
    "    model = RidgeCV(alphas = [0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6, 10, 30, 60])\n",
    "    model.fit(X_training,y)\n",
    "    alpha = model.alpha_\n",
    "    model = RidgeCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, alpha * .85, \n",
    "                          alpha * .9, alpha * .95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15,\n",
    "                          alpha * 1.25, alpha * 1.3, alpha * 1.35, alpha * 1.4], \n",
    "                cv = 10)\n",
    "    model.fit(X_training,y)\n",
    "    alpha = model.alpha_\n",
    "    print(\"RMSE for Ridge Regression with alpha {}: {:0.4f} (+/- {:0.4f})\".format(alpha, rmse_cv(model).mean(), rmse_cv(model).std() * 2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lasso_regression():\n",
    "    from sklearn.linear_model import LassoCV\n",
    "    model = LassoCV(alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, \n",
    "                          0.3, 0.6, 1], \n",
    "                max_iter = 50000, cv = 10)\n",
    "    model.fit(X_training,y)\n",
    "    alpha = model.alpha_\n",
    "    model = LassoCV(alphas = [alpha * .6, alpha * .65, alpha * .7, alpha * .75, alpha * .8, alpha * .85, \n",
    "                          alpha * .9, alpha * .95, alpha, alpha * 1.05, alpha * 1.1, alpha * 1.15,\n",
    "                          alpha * 1.25, alpha * 1.3, alpha * 1.35, alpha * 1.4], \n",
    "                    max_iter = 50000,cv = 10)\n",
    "    model.fit(X_training,y)\n",
    "    alpha = model.alpha_\n",
    "    print(\"RMSE for Lasso Regression with alpha {}: {:0.4f} (+/- {:0.4f})\".format(alpha, rmse_cv(model).mean(), rmse_cv(model).std() * 2))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elastic_regression():\n",
    "    from sklearn.linear_model import ElasticNetCV\n",
    "    model = ElasticNetCV(l1_ratio = [0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.85, 0.9, 0.95, 1],\n",
    "                          alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, \n",
    "                                    0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6], \n",
    "                          max_iter = 50000, cv = 10)\n",
    "    model.fit(X_training,y)\n",
    "    alpha = model.alpha_\n",
    "    ratio = model.l1_ratio_\n",
    "    model = ElasticNetCV(l1_ratio = [ratio * .85, ratio * .9, ratio * .95, ratio, ratio * 1.05, ratio * 1.1, ratio * 1.15],\n",
    "                          alphas = [0.0001, 0.0003, 0.0006, 0.001, 0.003, 0.006, 0.01, 0.03, 0.06, 0.1, 0.3, 0.6, 1, 3, 6], \n",
    "                          max_iter = 50000, cv = 10)\n",
    "    model.fit(X_training,y)\n",
    "    alpha = model.alpha_\n",
    "    ratio = model.l1_ratio_\n",
    "    print(\"RMSE for Elastic Regression with alpha {}, ratio {}: {:0.4f} (+/- {:0.4f})\".format(alpha, ratio, rmse_cv(model).mean(), rmse_cv(model).std() * 2))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partial_ls_regression():\n",
    "    from sklearn.cross_decomposition import PLSRegression\n",
    "    model = PLSRegression(n_components=2)\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"RMSE for PLS: {:0.4f} (+/- {:0.4f})\".format(rmse_cv(model).mean(), rmse_cv(model).std() * 2))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgboost_model():\n",
    "    import xgboost as xgb\n",
    "#     %matplotlib inline\n",
    "#     import matplotlib.pyplot as plt\n",
    "#     dtrain = xgb.DMatrix(X_train, label = y_train)\n",
    "#     params = {\"max_depth\":2, \"eta\":0.1}\n",
    "#     model = xgb.cv(params, dtrain,  num_boost_round=500, early_stopping_rounds=100)\n",
    "#     model.loc[30:,[\"train-rmse-mean\"]].plot()\n",
    "    model_xgb = xgb.XGBRegressor(n_estimators=400, max_depth=2, learning_rate=0.1) #the params were tuned using xgb.cv\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    print(\"RMSE for xgboost: {:0.4f} (+/- {:0.4f})\".format(rmse_cv(model_xgb).mean(), rmse_cv(model_xgb).std() * 2))\n",
    "    return model_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "training = load_data('./dataset/train.csv')\n",
    "testing = load_data('./dataset/test.csv')\n",
    "ID = testing['Id']\n",
    "import pandas as pd\n",
    "houses = pd.concat((training.loc[:,'MSSubClass':'SaleCondition'],\n",
    "                      testing.loc[:,'MSSubClass':'SaleCondition']))\n",
    "houses = fill_NA(houses)\n",
    "houses = redefine_category_numeric(houses)\n",
    "houses = add_new_features(houses)\n",
    "X = log_transform_skew(houses)\n",
    "X = standard_scaling_numeric_features(X)\n",
    "X = encode_category_features(X)\n",
    "X_training = X[:training.shape[0]]\n",
    "X_testing = X[training.shape[0]:]\n",
    "import numpy as np\n",
    "y = np.log(training['SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_training, y, test_size = 0.3, random_state = 0)\n",
    "# #standard scaling\n",
    "# X_train, stdSc_X, numerical_features = standard_scaling_numeric_features(X_train)\n",
    "# X_valid.loc[:,numerical_features] = stdSc_X.transform(X_valid.loc[:,numerical_features])\n",
    "# #robust scaling\n",
    "# X_train, rSc_X, numerical_features = robust_scaling_numeric_features(X_train)\n",
    "# X_valid.loc[:,numerical_features] = rSc_X.transform(X_valid.loc[:,numerical_features])\n",
    "# X_train = encode_category_features(X_train)\n",
    "# X_valid = encode_category_features(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Lasso Regression with alpha 0.0005099999999999999: 0.1316 (+/- 0.0291)\n",
      "RMSE for xgboost: 0.1267 (+/- 0.0140)\n"
     ]
    }
   ],
   "source": [
    "# lr = linear_regression()\n",
    "# ridge = ridge_regression()\n",
    "lasso = lasso_regression()\n",
    "# elastic = elastic_regression()\n",
    "# pls = partial_ls_regression()\n",
    "xgboost = xgboost_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.7\n",
    "preds = np.exp(ratio*xgboost.predict(X_testing)+(1-ratio)*lasso.predict(X_testing))\n",
    "solution = pd.DataFrame({\"Id\":ID, \"SalePrice\":preds})\n",
    "solution.to_csv(\"lasso_sol.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
